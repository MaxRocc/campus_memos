Algorithme et société
Patrick Loiseau et Oana Goga

Les algorithmes dans la perception populaire :

impression de boîte noire, secret
peur
envie de comprendre

***

La question fondamentale que ces 2 chercheurs se sont posée : 
La publicité en ligne (et notamment sur facebook) comment ça marche ?

Des données personnelles sont stockées, pourquoi ?

Indicateur : 
Dès qu’on voit « Suggested post » sur facebook, cela veut dire que quelqu’un a payé pour (via Create Ads).

« Sur facebook, n’importe qui peut devenir publicitaire »
Mode d’emploi : 
Choisir sa cible (critères d’âge, sexe, localisation géographique, etc.)
« Detailed targeting » via des attributs booléens 

Type d’entreprise : data brokers (ex. : Acxiom/Epsilom/Experian/DLX/Facebook)

D’où viennent les données utilisateur de facebook ? 
Des actions sur facebook : clics, actions, posts, etc.
Des informations de navigation des usagers
et des données hors connexion (via les autres data brokers)

exemple d’audience (cible) : personnes mariées, intéressées par l’achat d’une maison

* modèle PII : personal identity informations

Ciblage direct (même si on n’a pas d’adresse e-mail)

***

Les défis de la publicité en ligne 

1- respect de la vie privée
2- lutte contre la discrimination (manque de clarté de la part des acteurs de la publicité)
3- transparence (peu de résultats)

Facebook pixel : like button – collecte des données de façon invisible.
Facebook a « résolu » la « faille » liée à ce « pixel » - cf. annonce du 22 décembre 2017

Référence à IEEE (Institute of Electrical and Electronics Engineers) Security and Privacy 






Capitalisant sur leurs recherches, les deux chercheurs se sont demandé :

« Comment analyser les failles concernant la vie privée des plateformes de publicité en ligne de façon systématique ? »

***

Peut-on prévenir/détecter la discrimination des publicités en ligne ?

Ex. : peut se traduire par des offres d’emploi à salaire plus élevé pour les hommes que pour les femmes.

a variable « ethnic affinity » a changé de nom (« multi-cultural affinity »), hourra, son contenu n’a par contre pas changé…
« Est-ce que bannir « ethinc affinity » résoud le problème ? » la réponse des chercheurs est « non ».

Aux Etats-Unis, les listes d’électeurs sont publiques => c’est de la donnée gratuite exploitée facilement par les data-brokers. On peut aussi inférer l’appartenance ethnique d’une personne en analysant ses « likes » (typiquement, les musiques « noires » comme le blues, et son réseau d’amis).


Utilisation des données pour du lobbrying politique :
affaire Cambridge Analytica (Trump/Russie).

***

Une question pour laquelle tout un chacun a le droit d’avoir une réponse de qualité : « avec lesquelles de mes données suis-je ciblé ? » - bandeau « why am I seeing this ?» sur facebook ads.

Définir « Réponse de qualité » 
Explications incomplètes, trop vagues : 
	il faudrait préciser les dates, 
	à partir de quel PII (e-mail, téléphone, etc.)
	quid des données financières ? Des habitudes d’achat ?
Explications « malveillantes »

attributs « sensibles » - micro-targeting
comment déterminer l’importance d’un attribut ?
	Le plus sensible (vie privée)
	le plus (ou moins rare) 
	Celui qui a le plus d’influence sur le résultat


- AdAnalyst.mpi-sws.org : est un plug-in Chrome et Firefox
fait l’agrégation de données (les utilisateurs de ce pug-in donnent donc accès à leur compte facebook, pour qu’il récupère et analyse les données publicitaires)
compile les explications de facebook (pourquoi on a reçu telle ou telle publicité)

Ouverture vers des pistes d’évolution

Blockchain
Criteo
BID (?)

----------------------------------------------------------------------------------------------------------------

Biblio citée pendant la conférence : 

« Potential for discrimination in online targeted advertising » de Patrick Loiseau








